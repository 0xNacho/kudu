Compaction design notes
------------------------------------------------------------

Goal: Take two or more layers with overlapping key ranges, and merge
them into a new layer, while updates are concurrently being applied.
The output layer should also garbage collect (i.e reclaim storage from)
any rows which were deleted by the old layer.

------------------------------

Let's start with the simple example of compacting from 1 input layer to
1 output layer. This has the effect of removing deleted data and
applying updates. The compaction has two main phases:


  before
<----------|
              Phase 1:
              merging
           |-----------|
                         Phase 2: migrate
                         deltas
                       |---------------|
                                         compaction
                                         complete
                                       |----------->

|--------------  time ----------------------------->


System steady state:
  - Updates are applied only to the "source layer"

Transition into Phase 1:
  - Collect the current set of delta trackers (ie deltamemstore and files)
    for the layer. Create an iterator which includes these delta trackers.
  - Atomically with the above, create a new deltamemstore for any mutations
    that arrive during the compaction.

  - Because all new updates after the above steps go into a new deltamemstore,
    the iterator created is a pure snapshot which does not reflect updates
    which arrive during the compaction.

Phase 1: merge data:
  - Use the iterator created above to create a new set of data for the output
    layer. This will reflect any updates or deletes which arrived prior to the
    start of phase 1, but no updates or deletes which arrive during either
    phase of the compaction.
  - An additional integer column is created during this merge which contains
    an entry for each of the rows in the input layer. The value of this column
    is the corresponding row ID in the output layer.

    For example, if there were no deletes at all in the layer being compacted,
    this column will simply contain the sequence (1, 2, 3 ... N) where N is the
    number of rows in the input layer.

    If rowid 3 had been deleted, this will contain the sequence (1, 2, x, 3...)
    where 'x' is any special value indicating that the row has been deleted in
    the output.

  - Any mutations which arrive during this phase are applied only to the input
    layer's delta tracking structures. Because the merge operates on a snapshot,
    it will not take into account in the output layer.

Phase 2: migrate deltas from phase 1
  - Any mutations which arrive during this phase should be applied to both the
    input layer and the output layer. This is simple to do either by duplicating
    the key lookup into the output layer's key column, or by using the mapping
    column which was output as part of phase 1.

  - Because the merge output ignored any mutations which arrived during phase 1,
    we must now 'migrate' those mutations to the output layer. This can be done
    efficiently by collecting all of the deltas which were not included in the
    snapshot iterator, and merging their ordinal indexes with the mapping column
    created above. This translates the old rowid to the new rowid, so the same
    delta can be inserted into the output layer's delta tracking structures.

  - Any reads during this phase must be served from the input layer, since the
    output layer is missing the deltas which arrived during the merge phase (B).


End of Phase 2: swap layers
  - After Phase 2, the two layers have logically identical data, and they may
    be atomically swapped. Once the output layer has been swapped in, new updates
    only need to be applied to the output layer, and the old layer (as well as its
    mapping column) may be dropped.


Extending to multiple layers
------------------------------

The above algorithm can be extended to multiple layers equally well. At the beginning
of the compaction, each layer is snapshotted, and a snapshot iterator created. A merge
iterator then performs the merge of all of the snapshots in ascending key order, while
simultaneously outputting the rowid mapping for each of the old layers.

