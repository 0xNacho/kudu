---
title: Kudu FAQ
layout: default
active_nav: faq
---

<div class="row-fluid">
  <div class="col-lg-12 faq">
    <h2>Frequently Asked Questions</h2>

    <!-- A table of contents will be inserted here via Javascript (see below). -->
    <div id="faq_toc"></div>

    <dl>
      <dt id="faq_production">
        Is Kudu ready to be deployed into production yet?
      </dt>
      <dd>
        <p>
          We don't yet recommend this -- Kudu is currently in Beta. During the next few months we
          might have to break backwards compatibility with our current on-the-wire or on-disk
          formats or change public APIs. There is also still work to do to improve data durability
          and consistency. Kudu is currently in a good state for using in a proof-of-concept
          scenario for a future deployment.
        </p>
      </dd>
      <dt id="faq_ga">
        When can I expect GA or version 1.0?
      </dt>
      <dd>
        <p>
          There is no set timeline for general availability (GA). We are looking forward to working
          with the community to continue stabilizing and improving Kudu. We want to implement some
          critical missing features such as security and fill in other gaps before releasing Kudu
          1.0.
        </p>
      </dd>
      <dt id="faq_hbase">
        Why a new storage engine? Why not just improve Apache HBase to increase its scan speed?
      </dt>
      <dd>
        <p>
          Kudu shares some characteristics with HBase. Like HBase, it is a real-time store
          that supports key-indexed record lookup and mutation.
        </p>
        <p>
          However, Kudu's design differs from HBase in some fundamental ways:
        </p>
        <ul>
          <li>Kudu’s data model is more traditionally relational, while HBase is schemaless.</li>
          <li>Kudu’s on-disk representation is truly columnar and follows an entirely different
              storage design than HBase/BigTable.</li>
        </ul>
        <p>
          Making these fundamental changes in HBase would require a massive redesign, as opposed
          to a series of simple changes. HBase is the right design for many classes of
          applications and use cases and will continue to be the best storage engine for those
          workloads.
        </p>
      </dd>
      <dt id="faq_storage_format">
        How does Kudu store its data? Is the underlying data storage readable without
        going through Kudu?
      </dt>
      <dd>
        <p>
          Kudu accesses storage devices through the local filesystem, and works best with Ext4 or
          XFS. Kudu handles striping across <abbr title="just a bunch of disks">JBOD</abbr> mount
          points, and does not require <abbr title="redundant array of inexpensive disks">RAID</abbr>.
          Kudu's write-ahead logs (WALs) can be stored on separate locations from the data files,
          which means that WALs can be stored on <abbr title="solid state drives">SSDs</abbr> to
          enable lower-latency writes on systems with both SSDs and magnetic disks.
        </p>
        <p>
          Kudu's on-disk data format closely resembles Parquet, with a few differences to
          support efficient random access as well as updates. The underlying data is not
          directly queryable without using the Kudu client APIs. The Kudu team has worked hard
          to ensure that Kudu’s scan performance is performant, and has focused on storing data
          efficiently without making the trade-offs that would be required to allow direct access
          to the data files.
        </p>
      </dd>
      <dt id="faq_hdfs">
        Why doesn’t Kudu store its data in HDFS?
      </dt>
      <dd>
        <p>
          We considered a design which stored data on HDFS, but decided to go in a different
          direction, for the following reasons:
        </p>
        <ul>
          <li>Kudu handles replication at the logical level using Raft consensus, which makes
              HDFS replication redundant. We could have mandated a replication level of 1, but
              that is not HDFS's best use case.</li>
          <li>Filesystem-level snapshots provided by HDFS do not directly translate to Kudu support for
              snapshots, because it is hard to predict when a given piece of data will be flushed
              from memory. In addition, snapshots only make sense if they are provided on a per-table
              level, which would be difficult to orchestrate through a filesystem-level snapshot.</li>
          <li>HDFS security doesn’t translate to table- or column-level ACLs. Similar to HBase
              ACLs, Kudu would need to implement its own security system and would not get much
              benefit from the HDFS security model.</li>
          <li>Kudu’s scan performance is already within the same ballpark as Parquet files stored
              on HDFS, so there’s no need to accomodate reading Kudu’s data files directly.</li>
        </ul>
      </dd>
      <dt id="faq_colocate_hdfs">
        Can I colocate Kudu with HDFS on the same servers?
      </dt>
      <dd>Kudu can be colocated with HDFS on the same data disk mount points. This is similar
          to colocating Hadoop and HBase workloads. Kudu has been extensively tested
          in this type of configuration, with no stability issues. For latency-sensitive workloads,
          consider dedicating an SSD to Kudu's WAL files.
      </dd>
      <dt id="faq_transactions">
        Does Kudu support multi-row transactions?
      </dt>
      <dd>
        <p>
          No, Kudu does not support multi-row transactions at this time. However, single row
          operations are atomic within that row.
        </p>
      </dd>
      <dt id="faq_secondary_indexes">
        Does Kudu support secondary indexes?
      </dt>
      <dd>
        <p>
          No, Kudu does not support secondary indexes. Random access is only possible through the
          primary key. For analytic drill-down queries, Kudu has very fast single-column scans which
          allow it to produce sub-second results when querying across billions of rows on small
          clusters.
        </p>
      </dd>
      <dt id="faq_geo_distribute">
        Can a Kudu deployment be geo-distributed?
      </dt>
      <dd>
        <p>
          We don't recommend geo-distributing tablet servers this time because of the possibility
          of higher write latencies. In addition, Kudu is not currently aware of data placement.
          This could lead to a situation where the master might try to put all replicas
          in the same datacenter. We plan to implement the necessary features for geo-distribution
          in a future release.
        </p>
      </dd>
      <dt id="faq_kudu_shell">
        Where is the Kudu shell?
      </dt>
      <dd>
        <p>
          Kudu doesn’t yet have a command-line shell. If Kudu-compatible version of Impala is
          installed on your cluster then you can use it as a replacement for a shell. See also the
          docs for <a href="docs/kudu_impala_integration.html">Kudu Impala Integration</a>.
        </p>
      </dd>
      <dt id="faq_opensource">
        Is Kudu open source?
      </dt>
      <dd>Yes, Kudu is open source and licensed under the Apache Software License, version 2.0. The
          plan is to donate the project to the Apache Software Foundation for incubation. However,
          there is currently no committed timeline for this.
      </dd>
      <dt id="faq_initial_dev">
        Why was Kudu developed internally at Cloudera before its release?
      </dt>
      <dd>
        <p>
          We believe strongly in the value of open source for the long-term sustainable
          development of a project. We also believe that it is easier to work with a small
          group of colocated developers when a project is very young. Being in the same
          organization allowed us to move quickly during the initial design and development
          of the system.
        </p>
        <p>
          Now that Kudu is public, we look forward to working with a larger community during
          its next phase of development.
        </p>
      </dd>
      <dt id="faq_master_bottleneck">
        Is the Kudu Master a bottleneck?
      </dt>
      <dd>
        <p>
          Although the Master is not sharded, it is not expected to become a bottleneck for
          the following reasons.
        </p>
        <ul>
          <li>Like many other systems, the master is not on the hot path once the tablet
              locations are cached. </li>
          <li>The Kudu master process is extremely efficient at keeping everything in memory.
              In our testing on an 80-node cluster, the 99.99th percentile latency for getting
              tablet locations was on the order of hundreds of microseconds (not a typo). </li>
        </ul>
      </dd>
      <dt id="faq_managed_compactions">
        Should compactions be managed?
      </dt>
      <dd>
        <p>
          Compactions in Kudu are designed to be small and to always be running in the
          background. They operate under a (configurable) budget to prevent tablet servers
          from unexpectedly attempting to rewrite tens of GB of data at a time. Since compactions
          are so predictable, the only tuning knob available is the number of threads dedicated
          to flushes and compactions in the <strong>compaction maintenance manager</strong>.
        </p>
      </dd>
      <dt id="faq_security">
        How is security handled in Kudu?
      </dt>
      <dd>
        <p>
          Kudu has no security features at the moment, but we would like to have it ready for GA.
        </p>
      </dd>
      <dt id="faq_cap">
        Is Kudu a CP or AP system?
      </dt>
      <dd>
        <p>
          In the parlance of the CAP theorem, Kudu is a
          <abbr title="consistent (but not available) under network partitions">CP</abbr>
          type of storage engine. Writing to a tablet will be delayed if the server that hosts that
          tablet's leader replica fails until a quorum of servers is able to elect a new leader and
          acknowledge a given write request.
        </p>
        <p>
          Kudu gains the following properties by using Raft consensus:
        </p>
        <ul>
          <li>Leader elections are fast. As soon as the leader misses 3 heartbeats (half a second each), the
              remaining followers will elect a new leader which will start accepting operations right away.
              This whole process usually takes less than 10 seconds. </li>
          <li>Follower replicas don’t allow writes, but they do allow reads when fully up-to-date data is not
              required. Thus, queries against historical data (even just a few minutes old) can be
              sent to any of the replicas. If that replica fails, the query can be sent to another
              replica immediately. </li>
        </ul>
      </dd>
      <dt id="faq_consistency_tuning">
        Is Kudu’s consistency level tunable?
      </dt>
      <dd>
        <p>
          TODO fill when David is done with his doc.
        </p>
      </dd>
      <dt id="faq_jepsen">
        Where is Kudu’s Jepsen report?
      </dt>
      <dd>
        <p>
          No one has yet run <a href="https://github.com/aphyr/jepsen">Jepsen</a> on Kudu, but it
          would be a very welcome contribution. However, we know of several issues (TODO: need links
          to JIRAs) that need to be resolved before Kudu can pass a Jepsen serializable consistency
          test. We are committed to passing Jepsen, as well as other consistency-focused stress
          tests, before releasing Kudu 1.0.
        </p>
      </dd>
      <dt id="faq_dependencies">
        What are Kudu’s runtime dependencies?
      </dt>
      <dd>
        <p>
          Kudu itself doesn’t have any service dependencies and can run on a cluster without Hadoop,
          Impala, Spark, or any other project.
        </p>
        <p>
          If you want to use Impala, note that Impala depends on Hive’s metadata server, which has
          its own dependencies on Hadoop. It is not currently possible to have a pure Kudu+Impala
          deployment.
        </p>
      </dd>
      <dt id="faq_bulk_load">
        What’s the most efficient way to bulk load data into Kudu?
      </dt>
      <dd>
        <p>
          The easiest way to load data into Kudu is if the data is already managed by Impala.
          In this case, a simple <pre>INSERT INTO TABLE some_kudu_table SELECT * FROM some_csv_table</pre>
          does the trick.
        </p>
        <p>
          You can also use Kudu’s MapReduce OutputFormat to load data from HDFS, HBase, or
          any other data store that has an InputFormat.
        </p>
        <p>
          No tool is provided to load data directly into Kudu’s on-disk data format. We
          have found that for many workloads, the insert performance of Kudu is comparable
          to bulk load performance of other systems.
        </p>
      </dd>
      <dt id="faq_oltp">
        Should I use Kudu for OLTP-type workloads?
      </dt>
      <dd>
        <p>
          Kudu was designed and optimized for OLAP workloads and lacks features such as multi-row
          transactions and secondary indexing typically needed to support OLTP.
        </p>
      </dd>
      <dt id="faq_backup">
        How can I back up my Kudu data?
      </dt>
      <dd>
        <p>
          Kudu doesn’t yet have a built-in backup mechanism. Similar to bulk loading data,
          Impala can help if you have it available. You can use it to copy your data into
          Parquet format using a statement like:
        </p>
        <pre>INSERT INTO TABLE some_parquet_table SELECT * FROM kudu_table</pre>
        <p>
          then use
        </p>
        <pre>distcp</pre>
        <p>
          to copy the Parquet data to another cluster. While Kudu is in beta, we’re not
          expecting people to deploy mission-critical workloads on it yet.
        </p>
      </dd>
    </dl>
  </div>
</div>

<script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
  // Dynamically build a table of contents from the entries.
  var toc = "<ol>\n";
  $(".faq dl dt").each(function() {
    var title = this.innerText;
    var anchor = "#" + this.id;
    var item = '<li><a href="' + anchor + '">' + title + "</a></li>\n";
    toc += item;
  });
  toc += "</ol>\n";
  $("#faq_toc").prepend(toc);
}, false);
</script>
